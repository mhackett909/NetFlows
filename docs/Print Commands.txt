# BASE ENCODER WEIGHTS

print('===Encoder weights===')
print("Hidden layer")
print(np.round(np.transpose(autoencoder.layers[0].get_weights()[0]), 3), end="\n\n")
print("Latent layer")
print(np.round(np.transpose(autoencoder.layers[1].get_weights()[0]), 3), end="\n\n")

# BASE DECODER WEIGHTS

print('===Decoder weights===')
print("Hidden layer 2")
print(np.round(autoencoder.layers[2].get_weights()[0], 3), end="\n\n")
print("Output layer")
print(np.round(autoencoder.layers[3].get_weights()[0], 3), end="\n\n")

# DENSE TRANSPOSED DECODER WEIGHTS

print('===Decoder weights===')
print("Hidden layer 2")
print(np.round(autoencoder.layers[2].get_weights()[1], 3).T, end="\n\n")
print("Output layer")
print(np.round(autoencoder.layers[3].get_weights()[1], 3).T, end="\n\n")

# BASE ENCODER WEIGHTS NORM
print('Encoder weights norm')
w_encoder = np.round(autoencoder.layers[0].get_weights()[0], 2).T  # W in Figure 3.
print(np.round(np.sum(w_encoder ** 2, axis = 1),3), end="\n\n")
w_encoder = np.round(autoencoder.layers[1].get_weights()[0], 2).T  # W in Figure 3.
print(np.round(np.sum(w_encoder ** 2, axis = 1),3), end="\n\n")

# BASE DECODER WEIGHTS NORM
print('Decoder weights norm')
w_decoder = np.round(autoencoder.layers[2].get_weights()[0], 2)  
print(np.round(np.sum(w_decoder ** 2, axis = 1),3), end="\n\n")
w_decoder = np.round(autoencoder.layers[3].get_weights()[0], 2) 
print(np.round(np.sum(w_decoder ** 2, axis = 1),3), end="\n\n")

# DENSE TRANSPOSED DECODER WEIGHTS NORM
print('Decoder weights norm')
w_decoder = np.round(autoencoder.layers[2].get_weights()[1], 2).T  # W' in Figure 3.
print(np.round(np.sum(w_decoder ** 2, axis = 1),3), end="\n\n")
w_decoder = np.round(autoencoder.layers[3].get_weights()[1], 2).T  # W' in Figure 3.
print(np.round(np.sum(w_decoder ** 2, axis = 1),3), end="\n\n")

# BASE ENCODER DOT PRODUCT (ORTHOGONALITY)
print('Encoder weights dot products')
w_encoder = autoencoder.layers[0].get_weights()[0]
print(np.round(np.dot(w_encoder, w_encoder.T), 2), end="\n\n")
w_encoder = autoencoder.layers[1].get_weights()[0]
print(np.round(np.dot(w_encoder.T, w_encoder), 2), end="\n\n")

# BASE DECODER DOT PRODUCT (ORTHOGONALITY)
print('Decoder weights dot product')
w_decoder = autoencoder.layers[2].get_weights()[0]
print(np.round(np.dot(w_decoder.T, w_decoder), 2), end="\n\n")
w_decoder = autoencoder.layers[3].get_weights()[0]
print(np.round(np.dot(w_decoder.T, w_decoder), 2), end="\n\n")

# DENSE TRANSPOSED DECODER DOT PRODUCT (ORTHOGONALITY)
print('Decoder weights dot product')
w_decoder = autoencoder.layers[2].get_weights()[1]
print(np.round(np.dot(w_decoder.T, w_decoder), 2), end="\n\n")
w_decoder = autoencoder.layers[3].get_weights()[1]
print(np.round(np.dot(w_decoder.T, w_decoder), 2), end="\n\n")
